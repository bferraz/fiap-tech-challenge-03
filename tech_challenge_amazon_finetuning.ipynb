{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af9a15d7",
   "metadata": {},
   "source": [
    "# Tech Challenge - Fine-tuning para Produtos Amazon\n",
    "\n",
    "**Objetivo**: Executar fine-tuning de um foundation model usando o dataset AmazonTitles-1.3MM para gerar descri√ß√µes de produtos baseadas em t√≠tulos.\n",
    "\n",
    "**Dataset**: Utilizaremos o arquivo `trn.json.gz` que cont√©m t√≠tulos e descri√ß√µes de produtos da Amazon.\n",
    "\n",
    "**Modelo Escolhido**: Llama 3-8B com Unsloth para otimiza√ß√£o de treinamento.\n",
    "\n",
    "---\n",
    "\n",
    "## üìã √çndice\n",
    "1. [Configura√ß√£o Inicial](#1-configuracao-inicial)\n",
    "2. [Explora√ß√£o dos Dados](#2-exploracao-dos-dados)\n",
    "3. [Prepara√ß√£o do Dataset](#3-preparacao-do-dataset)\n",
    "4. [Teste do Modelo Base](#4-teste-do-modelo-base)\n",
    "5. [Fine-tuning](#5-fine-tuning)\n",
    "6. [Teste do Modelo Treinado](#6-teste-do-modelo-treinado)\n",
    "7. [Demonstra√ß√£o Interativa](#7-demonstracao-interativa)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebde9b9b",
   "metadata": {},
   "source": [
    "## 1. Configura√ß√£o Inicial\n",
    "\n",
    "### 1.1 Montagem do Google Drive\n",
    "Primeiro, vamos montar o Google Drive para acessar e salvar nossos arquivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e2786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Monta o Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Define o diret√≥rio de trabalho (usando o mesmo diret√≥rio onde est√° o arquivo de dados)\n",
    "WORK_DIR = '/content/drive/MyDrive/FineTunning/TechChallenge03'\n",
    "os.makedirs(WORK_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"‚úÖ Google Drive montado com sucesso!\")\n",
    "print(f\"üìÅ Diret√≥rio de trabalho: {WORK_DIR}\")\n",
    "\n",
    "# Verifica se o diret√≥rio existe e lista os arquivos\n",
    "if os.path.exists(WORK_DIR):\n",
    "    files_in_dir = os.listdir(WORK_DIR)\n",
    "    print(f\"üìã Arquivos no diret√≥rio: {files_in_dir}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Diret√≥rio n√£o existe, ser√° criado: {WORK_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e6adf7",
   "metadata": {},
   "source": [
    "### 1.2 Instala√ß√£o das Depend√™ncias\n",
    "\n",
    "Instalamos as bibliotecas necess√°rias:\n",
    "- **Unsloth**: Otimiza√ß√£o para fine-tuning eficiente\n",
    "- **Transformers**: Biblioteca principal para modelos de linguagem\n",
    "- **Datasets**: Para manipula√ß√£o de datasets\n",
    "- **TRL**: Para treinamento de modelos de linguagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741f4950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala√ß√£o das depend√™ncias principais\n",
    "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "!pip install --no-deps xformers \"trl<0.9.0\" peft accelerate bitsandbytes\n",
    "!pip install transformers datasets torch\n",
    "\n",
    "print(\"‚úÖ Todas as depend√™ncias foram instaladas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964444a4",
   "metadata": {},
   "source": [
    "### 1.3 Importa√ß√£o das Bibliotecas e Configura√ß√µes Iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadc67db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necess√°rios\n",
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, load_dataset\n",
    "import torch\n",
    "from transformers import TrainingArguments, TextStreamer\n",
    "from trl import SFTTrainer\n",
    "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Bibliotecas importadas com sucesso!\")\n",
    "print(f\"üî• CUDA dispon√≠vel: {torch.cuda.is_available()}\")\n",
    "print(f\"üíæ GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N√£o dispon√≠vel'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e692fdc",
   "metadata": {},
   "source": [
    "### 1.4 Configura√ß√µes do Modelo e Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934b779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura√ß√µes principais\n",
    "CONFIG = {\n",
    "    # Configura√ß√µes do modelo\n",
    "    'model_name': \"unsloth/llama-3-8b-bnb-4bit\",\n",
    "    'max_seq_length': 2048,\n",
    "    'dtype': None,  # Ser√° determinado automaticamente\n",
    "    'load_in_4bit': True,\n",
    "    \n",
    "    # Configura√ß√µes do dataset\n",
    "    'data_file': '/content/drive/MyDrive/FineTunning/TechChallenge03/trn.json.gz',\n",
    "    'sample_size': 10000,  # N√∫mero de amostras para treinamento (pode ajustar)\n",
    "    'test_size': 100,  # N√∫mero de amostras para teste\n",
    "    \n",
    "    # Configura√ß√µes do fine-tuning\n",
    "    'lora_r': 16,\n",
    "    'lora_alpha': 16,\n",
    "    'lora_dropout': 0,\n",
    "    'max_steps': 100,  # Ajuste conforme necess√°rio\n",
    "    'learning_rate': 2e-4,\n",
    "    'batch_size': 2,\n",
    "    'gradient_accumulation_steps': 4,\n",
    "    \n",
    "    # Caminhos - usando o mesmo diret√≥rio base\n",
    "    'base_dir': '/content/drive/MyDrive/FineTunning/TechChallenge03',\n",
    "    'output_dir': '/content/drive/MyDrive/FineTunning/TechChallenge03/outputs',\n",
    "    'model_save_path': '/content/drive/MyDrive/FineTunning/TechChallenge03/amazon_model',\n",
    "}\n",
    "\n",
    "# Cria√ß√£o dos diret√≥rios\n",
    "os.makedirs(CONFIG['base_dir'], exist_ok=True)\n",
    "os.makedirs(CONFIG['output_dir'], exist_ok=True)\n",
    "os.makedirs(CONFIG['model_save_path'], exist_ok=True)\n",
    "\n",
    "print(\"‚öôÔ∏è Configura√ß√µes definidas:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db812510",
   "metadata": {},
   "source": [
    "## 2. Explora√ß√£o dos Dados\n",
    "\n",
    "### 2.1 Upload do Arquivo de Dados\n",
    "\n",
    "Primeiro, voc√™ precisa fazer upload do arquivo `trn.json.gz` para o Colab.\n",
    "Execute a c√©lula abaixo e fa√ßa upload do arquivo quando solicitado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26bfe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define o caminho para o arquivo no Google Drive\n",
    "DATA_FILE_PATH = '/content/drive/MyDrive/FineTunning/TechChallenge03/trn.json.gz'\n",
    "\n",
    "# Verifica se o arquivo existe\n",
    "if os.path.exists(DATA_FILE_PATH):\n",
    "    print(\"‚úÖ Arquivo trn.json.gz encontrado no Google Drive!\")\n",
    "    print(f\"üìÅ Caminho: {DATA_FILE_PATH}\")\n",
    "    \n",
    "    # Verifica o tamanho do arquivo\n",
    "    file_size = os.path.getsize(DATA_FILE_PATH)\n",
    "    print(f\"üìä Tamanho do arquivo: {file_size / (1024*1024):.1f} MB\")\n",
    "else:\n",
    "    print(\"‚ùå Arquivo n√£o encontrado no caminho especificado.\")\n",
    "    print(f\"‚ùå Caminho verificado: {DATA_FILE_PATH}\")\n",
    "    print(\"üí° Certifique-se de que o arquivo trn.json.gz est√° no diret√≥rio correto do Google Drive.\")\n",
    "    DATA_FILE_PATH = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60dc203",
   "metadata": {},
   "source": [
    "### 2.2 Carregamento e An√°lise Inicial dos Dados\n",
    "\n",
    "Vamos carregar o dataset e analisar sua estrutura para entender melhor os dados com que estamos trabalhando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120a6b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_amazon_data(file_path, sample_size=None):\n",
    "    \"\"\"\n",
    "    Carrega os dados do arquivo JSON comprimido\n",
    "    \n",
    "    Args:\n",
    "        file_path: Caminho para o arquivo trn.json.gz\n",
    "        sample_size: N√∫mero de amostras a carregar (None para carregar tudo)\n",
    "    \n",
    "    Returns:\n",
    "        Lista de dicion√°rios com os dados\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    print(f\"üìñ Carregando dados de {file_path}...\")\n",
    "    \n",
    "    try:\n",
    "        with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if sample_size and i >= sample_size:\n",
    "                    break\n",
    "                    \n",
    "                try:\n",
    "                    json_obj = json.loads(line.strip())\n",
    "                    data.append(json_obj)\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "                    \n",
    "                # Progress update\n",
    "                if (i + 1) % 1000 == 0:\n",
    "                    print(f\"  Carregadas {i + 1} amostras...\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao carregar dados: {e}\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"‚úÖ Dados carregados com sucesso! Total: {len(data)} amostras\")\n",
    "    return data\n",
    "\n",
    "# Carrega uma amostra dos dados para an√°lise inicial\n",
    "if DATA_FILE_PATH:\n",
    "    sample_data = load_amazon_data(DATA_FILE_PATH, sample_size=5000)\n",
    "else:\n",
    "    print(\"‚ùå Arquivo de dados n√£o dispon√≠vel. Execute a c√©lula de upload primeiro.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46600d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise da estrutura dos dados\n",
    "if sample_data:\n",
    "    print(\"üîç AN√ÅLISE DA ESTRUTURA DOS DADOS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Exemplo de uma amostra\n",
    "    print(\"üìù Exemplo de uma amostra:\")\n",
    "    sample_item = sample_data[0]\n",
    "    for key, value in sample_item.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    \n",
    "    # Estat√≠sticas gerais\n",
    "    print(f\"üìä ESTAT√çSTICAS GERAIS:\")\n",
    "    print(f\"  Total de amostras carregadas: {len(sample_data)}\")\n",
    "    \n",
    "    # Verifica campos obrigat√≥rios\n",
    "    required_fields = ['title', 'content']\n",
    "    valid_samples = []\n",
    "    \n",
    "    for item in sample_data:\n",
    "        if all(field in item and item[field] for field in required_fields):\n",
    "            valid_samples.append(item)\n",
    "    \n",
    "    print(f\"  Amostras v√°lidas (com t√≠tulo e conte√∫do): {len(valid_samples)}\")\n",
    "    print(f\"  Taxa de amostras v√°lidas: {len(valid_samples)/len(sample_data)*100:.1f}%\")\n",
    "    \n",
    "    # Armazena as amostras v√°lidas\n",
    "    sample_data = valid_samples\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Nenhum dado foi carregado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90519116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise detalhada dos textos\n",
    "if sample_data:\n",
    "    print(\"üìè AN√ÅLISE DE COMPRIMENTO DOS TEXTOS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Calcula estat√≠sticas de comprimento\n",
    "    title_lengths = [len(item['title']) for item in sample_data]\n",
    "    content_lengths = [len(item['content']) for item in sample_data]\n",
    "    \n",
    "    title_words = [len(item['title'].split()) for item in sample_data]\n",
    "    content_words = [len(item['content'].split()) for item in sample_data]\n",
    "    \n",
    "    print(\"üìù Comprimento em caracteres:\")\n",
    "    print(f\"  T√≠tulos - M√≠n: {min(title_lengths)}, M√°x: {max(title_lengths)}, M√©dia: {np.mean(title_lengths):.1f}\")\n",
    "    print(f\"  Conte√∫do - M√≠n: {min(content_lengths)}, M√°x: {max(content_lengths)}, M√©dia: {np.mean(content_lengths):.1f}\")\n",
    "    \n",
    "    print(\"\\nüî§ Comprimento em palavras:\")\n",
    "    print(f\"  T√≠tulos - M√≠n: {min(title_words)}, M√°x: {max(title_words)}, M√©dia: {np.mean(title_words):.1f}\")\n",
    "    print(f\"  Conte√∫do - M√≠n: {min(content_words)}, M√°x: {max(content_words)}, M√©dia: {np.mean(content_words):.1f}\")\n",
    "    \n",
    "    # Exemplos de diferentes tamanhos\n",
    "    print(\"\\nüìã EXEMPLOS DE PRODUTOS:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # T√≠tulo mais curto\n",
    "    shortest_idx = title_lengths.index(min(title_lengths))\n",
    "    print(f\"üî∏ T√≠tulo mais curto ({len(sample_data[shortest_idx]['title'])} chars):\")\n",
    "    print(f\"  T√≠tulo: {sample_data[shortest_idx]['title']}\")\n",
    "    print(f\"  Conte√∫do: {sample_data[shortest_idx]['content']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 30)\n",
    "    \n",
    "    # T√≠tulo mais longo\n",
    "    longest_idx = title_lengths.index(max(title_lengths))\n",
    "    print(f\"üî∏ T√≠tulo mais longo ({len(sample_data[longest_idx]['title'])} chars):\")\n",
    "    print(f\"  T√≠tulo: {sample_data[longest_idx]['title']}\")\n",
    "    print(f\"  Conte√∫do: {sample_data[longest_idx]['content'][:200]}...\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 30)\n",
    "    \n",
    "    # Exemplo aleat√≥rio\n",
    "    import random\n",
    "    random_idx = random.randint(0, len(sample_data)-1)\n",
    "    print(f\"üî∏ Exemplo aleat√≥rio:\")\n",
    "    print(f\"  T√≠tulo: {sample_data[random_idx]['title']}\")\n",
    "    print(f\"  Conte√∫do: {sample_data[random_idx]['content']}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Nenhum dado dispon√≠vel para an√°lise.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252fb874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√µes\n",
    "if sample_data:\n",
    "    print(\"üìä CRIANDO VISUALIZA√á√ïES DOS DADOS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Configura√ß√£o do matplotlib\n",
    "    plt.style.use('default')\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('An√°lise do Dataset Amazon Products', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Gr√°fico 1: Distribui√ß√£o do comprimento dos t√≠tulos\n",
    "    axes[0,0].hist(title_lengths, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[0,0].set_title('Distribui√ß√£o - Comprimento dos T√≠tulos (caracteres)')\n",
    "    axes[0,0].set_xlabel('N√∫mero de caracteres')\n",
    "    axes[0,0].set_ylabel('Frequ√™ncia')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Gr√°fico 2: Distribui√ß√£o do comprimento do conte√∫do\n",
    "    axes[0,1].hist(content_lengths, bins=30, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "    axes[0,1].set_title('Distribui√ß√£o - Comprimento do Conte√∫do (caracteres)')\n",
    "    axes[0,1].set_xlabel('N√∫mero de caracteres')\n",
    "    axes[0,1].set_ylabel('Frequ√™ncia')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Gr√°fico 3: Distribui√ß√£o de palavras nos t√≠tulos\n",
    "    axes[1,0].hist(title_words, bins=20, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "    axes[1,0].set_title('Distribui√ß√£o - Palavras nos T√≠tulos')\n",
    "    axes[1,0].set_xlabel('N√∫mero de palavras')\n",
    "    axes[1,0].set_ylabel('Frequ√™ncia')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Gr√°fico 4: Rela√ß√£o entre t√≠tulo e conte√∫do\n",
    "    axes[1,1].scatter(title_lengths, content_lengths, alpha=0.5, color='purple', s=10)\n",
    "    axes[1,1].set_title('Rela√ß√£o: T√≠tulo vs Conte√∫do (caracteres)')\n",
    "    axes[1,1].set_xlabel('Comprimento do t√≠tulo')\n",
    "    axes[1,1].set_ylabel('Comprimento do conte√∫do')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Visualiza√ß√µes criadas com sucesso!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Nenhum dado dispon√≠vel para visualiza√ß√£o.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
