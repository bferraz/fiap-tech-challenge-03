# Diagn√≥stico: Fine-tuning n√£o est√° funcionando

## Problema atual
Resultados id√™nticos entre modelo base e adapter no Streamlit.

## Altera√ß√µes feitas no Streamlit

1. **Adicionado logs de debug**: O app agora mostra se o adapter est√° carregado corretamente
2. **Verifica√ß√£o PEFT**: Confirma se PEFT est√° ativo durante a gera√ß√£o
3. **Status do modelo**: Mostra se est√° em modo eval

## Como diagnosticar

### 1. Execute o Streamlit e observe os logs:
```
‚úì Adapter carregado de: [caminho]
‚úì PEFT config detectado: ['default']
‚úì Adapters ativos: ['default']
üîß PEFT ativo com 1 adapter(s) | ‚úì Modelo em modo eval
```

Se n√£o aparecer "PEFT ativo", o adapter n√£o est√° sendo aplicado.

### 2. Teste com par√¢metros determin√≠sticos:
- `do_sample = False` (desabilitar)
- `temperature = 0.1` (baixo)
- `top_p = 1.0` (alto)

Se ainda assim os resultados forem id√™nticos, o problema n√£o √© aleatoriedade.

### 3. Teste t√≠tulos espec√≠ficos do treino:
Use t√≠tulos que voc√™ SABE que estavam no dataset de treino para ver se h√° overfitting.

## Poss√≠veis causas e solu√ß√µes

### Causa 1: Dataset muito pequeno (200 registros ‚Üí 71 de treino)
**Diagn√≥stico**: 71 exemplos podem n√£o ser suficientes para TinyLlama aprender padr√µes significativos.

**Solu√ß√£o**: 
- Aumente `RECORDS_TO_FINETUNNING` para pelo menos 2000-5000
- No notebook: execute apenas as c√©lulas de treino (pule baseline se quiser ir r√°pido)

### Causa 2: Learning rate muito alto/baixo
**Diagn√≥stico**: LR=2e-4 pode ser alto demais para um dataset pequeno.

**Solu√ß√£o**:
```python
# No notebook, c√©lula de par√¢metros:
OSS_LR = 1e-4  # ou 5e-5 (mais conservador)
```

### Causa 3: √âpocas insuficientes
**Diagn√≥stico**: 2 √©pocas podem n√£o ser suficientes.

**Solu√ß√£o**:
```python
OSS_EPOCHS = 3  # ou 4
```

### Causa 4: LoRA rank muito baixo
**Diagn√≥stico**: r=16 pode ser insuficiente para capturar mudan√ßas.

**Solu√ß√£o**:
```python
LORA_R = 32  # ou 64
LORA_ALPHA = 32  # mant√©m propor√ß√£o 1:1
```

### Causa 5: Modelo n√£o convergiu
**Diagn√≥stico**: Loss n√£o diminuiu durante treino.

**Solu√ß√£o**: Verificar os logs de treino no Colab:
- Loss deve diminuir gradualmente
- Eval loss deve acompanhar train loss
- Se loss n√£o muda, aumentar LR ou verificar dados

## Teste r√°pido recomendado

1. **Aumente dataset**:
```python
RECORDS_TO_FINETUNNING = 2000  # no lugar de 200
```

2. **Ajuste hiperpar√¢metros**:
```python
OSS_LR = 1e-4
OSS_EPOCHS = 3
LORA_R = 32
LORA_ALPHA = 32
```

3. **Execute treino** e observe se loss diminui consistentemente

4. **Teste no Streamlit** com:
   - do_sample = False
   - T√≠tulos espec√≠ficos que estavam no treino
   - Observe os logs de debug

## Verifica√ß√£o final

### Teste A/B direto:
```python
# No final do notebook, adicione c√©lula de teste:
test_title = "Smartphone with 5G connectivity"
prompt = f"[SYSTEM]\nYou are an assistant that writes detailed product descriptions from a given title.\n[USER]\nTitle: {test_title}\n[ASSISTANT]\n"

# Base
base_out = generate_batch([prompt], do_sample=False)[0]
print("BASE:", base_out)

# Fine-tuned (usando model ap√≥s treino)
ft_out = generate_batch([prompt], do_sample=False)[0]  
print("FINE-TUNED:", ft_out)
```

Se forem id√™nticos, o treino realmente n√£o funcionou.

## Quando considerar bem-sucedido

- Logs mostram "PEFT ativo" no Streamlit
- Resultados diferentes entre base e adapter (mesmo com seed fixo)
- Adapter gera descri√ß√µes mais detalhadas/espec√≠ficas
- Loss diminuiu durante treino no Colab

## √öltima alternativa: teste com merged model

Se adapter continuar problem√°tico, use o modelo merged:
1. Execute a c√©lula de merge no Colab
2. No Streamlit, escolha "Fine-tuned (merged)"
3. Compare base vs merged

O merged elimina vari√°veis da camada PEFT.